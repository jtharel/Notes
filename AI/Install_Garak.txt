#garak works with language models and any tech using them to determine where the security holes can be with each solution. 

#Install on Mac:

virtualenv garak
cd garak
source bin/activate 

pip install setuptools
pip install Cmake
git clone https://github.com/google/sentencepiece.git 
cd sentencepiece
mkdir build
cd build
cmake .. -DSPM_ENABLE_SHARED=OFF -DCMAKE_INSTALL_PREFIX=./root
make install
cd ../python
python setup.py bdist_wheel
pip install dist/sentencepiece*.whl
cd ../..

python -m pip install -U garak

#test run:
python -m garak --target_type test.Blank --probes test.Test


#Using Garak:

python3 -m garak --list_probes		-> shows test cases


Create file garak-config.json:
{"rest.RestGenerator":
    {
        "name": "example service",
        "uri": "https://example.ai/llm",
        "method": "post",
        "headers":{
            "X-Authorization": "$KEY",
	    "Content-Type": "application/json"
        },
        "req_template_json_object":{
            "text":"$INPUT"
        },
        "response_json": true,
        "response_json_field": "text"
    }
}

# $INPUT is the location that grok will inject it's prompts/attacks
# Another example of this might look like this:
# "req_template_json_object":{
#     "api_provider":"groq",
#     "chat_history":
#         [
#             {"role":"user","content":"$INPUT"}
#         ]

# The response_json_field "text" is the parameter that contains the response that 
# will be evaluated to see if the attack worked

# $KEY value is acquired from an environment variable on the system.
# export REST_API_KEY=<authorization_key>
# export OPENAI_API_KEY=<auth_key> ??

python3 -m garak --target_type huggingface --target_name gpt2 -G ./garak-config.json --probes lmrc.Profanity

python3 -m garak --target_type huggingface --target_name ibm-granite/granite-3.1-1b-a400m-instruct  -G ./garak-config.json --probes lmrc.Profanity

python3 -m garak --target_type openai --target_name gpt-3.5-turbo -G ./garak-config.json --probes xss.MarkdownImageExfil

# python3 -m garak --list_probes		-> shows test cases
# To run all the tests within the plugin family, use -p <pluginFamilyName>
# to only run one test within the plugin family, use -p <pluginFamilyName>.<specificPluginName>

#View Report:
python3 -m garak.analyze --report /home/<username>/.local/share/garak/garak_runs/garak.YOUR_REPORT_ID.report.jsonl



# Garak is installed in Linux VM, Burp is running on Host OS
# This will allow you to run Garak through burp and not have to worry about SSL errors 
# since ollama is running locally in Linux
# In Linux, Install ollama:
curl -fsSL https://ollama.com/install.sh | sh
ollama pull tinylama

# run ollama and garak:
ollama run tinylama &
export HTTPS_PROXY="HTTP://192.168.1.251:8080"
export HTTP_PROXY="HTTP://192.168.1.251:8080"
export NO_PROXY="localhost,127.0.0.1"
python3 -m garak --target_type ollama --target_name tinyllama -G ./garak-config.json --probes ansiescape.AnsiEscaped


Proxy - add to garak-config.json file?:
{
  "rest.RestGenerator": {
    "uri": "https://your-internal-llm.com/v1/chat",
    "method": "post",
    "proxies": {
      "http": "http://10.10.1.10:3128",
      "https": "http://10.10.1.10:1080"
    },
    "verify_ssl": false
  }
}
