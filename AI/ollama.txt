https://ollama.com/

ollama run <model name>

models: https://ollama.com/search


ollama run deepseek-r1
or 
ollama run llama3
or
ollama run llama2-uncensored

APIs:
Generate a response
curl http://localhost:11434/api/generate -d '{
  "model": "llama3.2",
  "prompt":"Why is the sky blue?"
}'

Chat with a model
curl http://localhost:11434/api/chat -d '{
  "model": "llama3.2",
  "messages": [
    { "role": "user", "content": "why is the sky blue?" }
  ]
}'
